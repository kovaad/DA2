---
title: "DA2 - Hotels Europe Analysis"
author: "Adam Kovacs, Nam Son Nguyen"
date: "12/04/2021"
geometry: margin=1.8cm
fontsize: 9pt
output: 
  pdf_document:
    fig_caption: true
    latex_engine: xelatex
header-includes: |
  \usepackage{titling}
  \setlength{\droptitle}{-5em}
---

## Introduction

In this project, we analyze the [**hotels-europe dataset**](https://osf.io/r6uqb/) to investigate how high rating is related to the other hotel features in the data. We estimate linear probability, logit, and probit models with distance and stars as explanatory variables. 

```{r import, echo=FALSE, message=FALSE}
#clear memory
rm(list=ls())

#import packages
if (!require(pacman)){
  install.packages("pacman")
}

pacman::p_load(tidyverse, modelsummary, kableExtra, fixest, estimatr, mfx)

# import data
hfeatures <- read_csv('https://osf.io/utwjs/download')

#table(hfeatures$city)

```

```{r filter, echo=FALSE}

#filter on London and create binary variable highly_rated
london <- hfeatures %>%
          filter(city_actual == "London") %>%
          mutate(highly_rated = ifelse(rating >= 4, 1, 0)) %>%
          dplyr::select(highly_rated, stars, distance, accommodation_type) %>% 
          na.omit()

```

## Descriptive statistics

```{r descriptives, echo=FALSE}

#create 5th and 95th percentiles

P95 <- function(x){quantile(x,0.95,na.rm=T)}
P05 <- function(x){quantile(x,0.05,na.rm=T)}

#create descriptive table
datasummary( (`Highly rated` = highly_rated ) + (`Distance from center` = distance ) + 
               (`Stars` = stars ) ~
               Mean + Median + SD + Min + Max + P05 + P95, 
             data = london,
             title = 'Descriptive stats of main variables' ) %>% 
  kableExtra::kable_styling(latex_options = "hold_position")

```
Our descriptive table indicates that 43% of the hotels in London are highly rates. Regarding the other two variables, the distribution of distance from center is right-skewed with an average of 2.60 kilometers, while we can infer a roughly normal distribution (mean ~ median) for stars with an average of 3.45.

## Regressions

```{r, echo=FALSE, message=FALSE, warning = FALSE}
#assess accomodation type as other explanatory variable
#unique(london$accommodation_type)

#create accomodation type as explanatory variable for regressions
london <- within(london, accommodation_type<- relevel(as.factor(accommodation_type), ref = "Hotel"))

#linear probability model
lpm <- feols(highly_rated ~ distance + stars + accommodation_type, data=london, vcov = 'hetero')
#logit model
logit <- feglm(highly_rated ~ distance + stars + accommodation_type, data=london, family = "logit", vcov = 'hetero')
#logit model marginal effects
logitm <- logitmfx(highly_rated ~ distance + stars + accommodation_type, data=london, atmean = F, robust = T)
#probit model
probit <- feglm(highly_rated ~ distance + stars + accommodation_type, data=london, family = binomial(link = "probit"), vcov = 'hetero')
#probit model marginal effects
probitm <- probitmfx(highly_rated ~ distance + stars + accommodation_type, data=london, atmean = F, robust = T)
#summary of models
msummary(list("LPM" = lpm, "Logit" = logit, "Logit_marginal" = logitm, "Probit" =  probit, "Probit_marginal" = probitm),
         fmt="%.2f",
         gof_omit = 'DF|Deviance|Log.Lik.|F|R2 Adj.|R2 Within|R2 Pseudo|R',
         stars=c('*' = .05, '**' = .01),
         estimate = "{estimate} ({std.error}){stars}",
         statistic = NULL,
         coef_rename = c("(Intercept)" = "Constant",
                         "distance" = "Distance",
                         "stars" = "Stars",
                         "accommodation_typeApart-hotel" = "Apart-hotel",
                         "accommodation_typeApartment" = "Apartment",
                         "accommodation_typeBed and breakfast" = "Bed and breakfast",
                         "accommodation_typeGuest House" = "Guest House",
                         "accommodation_typeHostel" = "Hostel",
                         "accommodation_typeInn" = "Inn"),
         title = "Highly rated") %>% 
        column_spec(1:6, width = "7em") %>%
        kable_classic(full_width = F, position = "center" )

```

From the linear probability model, we can interpret the coefficients the following way: Being 1 km farther away from the city center surprisingly increases the probability of high rating by 2 percentage points. This is statistically significant at 5% significance level. Having 1 more star increases the likelihood of high rating by 33 percentage points. This is statistically significant even at 1% significance level. As for the type of accommodation, we chose hotels as our base category, because it has by far the most observations, so standard errors are lower and there are more significant results. In this LPM, the apartment and bed and breakfast are the two categories that are statistically significant at 1% level, and both have a lower probability by 17 and 16 percentage points on average compared to hotels with the same attributes to be highly rated. The guest house is another accommodation type that is significant at 5% level, it has on average a 12% less likelihood of being highly rate compared to a hotel with same attributes. 
Next, let us turn to the average marginal differences given by the logit and probit models. We can see that with regards to distance, they are exactly the same as the LMP model. As for stars, having 1 more increases the likelihood of high rating by only 30 percentage points (compared to 33 estimated by the LPM). Among the accommodation types, in these models only Apartment is significant at 1% level, which has a 14 percentage points lower likelihood o higher rating than hotels (compared to 17 in the LPM). The bed and breakfast is also significant in 5% level in both models, having a marginal effect of -15 and -14 percentage points in the logit and probit models respectively (compared to the -16 estimated by the LPM). Finally, the guest house is only significant at 5% by the logit model, such a type of accommodation with the same attributes otherwise as a hotel has on average a 12 percentage point loer likelihood of being highly rated.

## Goodness of fit

```{r, include=F, echo=FALSE, message=TRUE, warning=TRUE}

fitstat_register("brier", function(x){mean(x$residual^2)}, "Brier score")
fitstat_register("logloss", function(x){
  log_id <- !is.na( x$fitted.values ) & x$fitted.values != 1 & x$fitted.values != 0
  y   <- x$fitted.values[ log_id ] + x$residuals[ log_id ]
  lp  <- log( x$fitted.values[log_id] )
  lnp <- log( 1 - x$fitted.values[log_id] )
  nobs <- sum( log_id )
  return( 1 / nobs * sum( y * lp + ( 1 - y ) * lnp ) )
}, "log-loss")

etable( lpm, logit, probit , drop = "stars|distance|accommodation",fitstat = ~ r2 + brier + pr2 + logloss, tex=T)

```

\begin{table}
\caption{Goodness of fit metrics}
\begin{center}
\begin{tabular}{lccc}
   \tabularnewline\midrule\midrule
   Dependent Variable: & \multicolumn{3}{c}{highly\_rated}\\
   Model:       & (1)             & (2)            & (3)\\
                &  LPM            & Logit          & Probit\\
   \midrule \emph{Fit statistics} &   &   &  \\
   R$^2$        & 0.33602         &                & \\
   Brier score  & 0.16250         & 0.15770        & 0.15832\\
   Pseudo R$^2$ & 0.28630         & 0.28646        & 0.28372\\
   log-loss     & NaN             & -0.48705       & -0.48892\\
   \midrule\midrule\multicolumn{4}{l}{\emph{Heteroskedasticity-robust standard-errors in parentheses}}\\
   \multicolumn{4}{l}{\emph{Signif. Codes: ***: 0.01, **: 0.05, *: 0.1}}\\
\end{tabular}
\end{center}
\end{table}

```{r, echo=FALSE, message=FALSE, warning = FALSE}

#Append predictions to table
london$pred_lpm <- predict( lpm )
london$pred_logit <- predict( logit, type="response" )
london$pred_probit <- predict( probit, type="response" )

```

```{r, echo=FALSE, fig.align='center', warning = FALSE}

#Distribution of predicted values
#Some falls outside the [0,1] interval
ggplot(data=london, aes(x=pred_lpm)) +
  geom_histogram(aes(y=..count../sum(..count..)), binwidth = 0.05, fill = "lightgreen", color = "green") +
  coord_cartesian(xlim = c(-0.4, 1.1)) +
  labs(title = "Distribution of Predicted Probabilities",
       x = "Predicted probability of being highly rated (LPM)",
       y = "Percent") +
  scale_y_continuous(expand = c(0.00,0.0), limits = c(0,0.2), breaks = seq(0, 0.2, 0.05), labels = scales::percent_format(accuracy = 1)) +
  scale_x_continuous(expand = c(0.001,0.01), limits = c(-0.4,1.1), breaks = seq(-0.4,1.1, 0.2)) +
  theme_bw()

#min(london$pred_lpm)
#max(london$pred_lpm)
#london %>% filter(pred_lpm < quantile(pred_lpm,0.01)) %>% summarise(avg_stars = mean(stars))
#london %>% filter(pred_lpm < quantile(pred_lpm,0.01)) %>% summarise(avg_dist = mean(distance))
#Mode <- function(x) {ux <- unique(x)
#     ux[which.max(tabulate(match(x, ux)))]}
#london %>% filter(pred_lpm < quantile(pred_lpm,0.01)) %>% summarise(mode = Mode(accommodation_type))
#london %>% filter(pred_lpm > quantile(pred_lpm,0.01)) %>% summarise(avg_stars = mean(stars))
#london %>% filter(pred_lpm > quantile(pred_lpm,0.01)) %>% summarise(avg_dist = mean(distance))
#london %>% filter(pred_lpm > quantile(pred_lpm,0.01)) %>% summarise(mode = Mode(accommodation_type))

#Prediction evaluation
#Logit, probit estimates higher values for higher lpm, and lower for lower LPM
ggplot(data = london) +
  geom_point(aes(x=pred_lpm, y=pred_probit, color="Probit"), size=0.4,  shape=16) +
  geom_point(aes(x=pred_lpm, y=pred_logit,  color="Logit"), size=0.4,  shape=16) +
  geom_line(aes(x=pred_lpm, y=pred_lpm,    color="45 degree line"), size=0.4) +
  labs(title = "Model Comparison",
       x = "Predicted probability of staying healthy (LPM)",
       y="Predicted probability")+
  scale_y_continuous(expand = c(0.00,0.0), limits = c(0,1), breaks = seq(0,1,0.1)) +
  scale_x_continuous(expand = c(0.00,0.0), limits = c(0,1), breaks = seq(0,1,0.1)) +
  theme(legend.position=c(0.55,0.08),
        legend.direction = "horizontal",
        legend.title = element_blank(),
        legend.text = element_text(size = 4))

#min(london$pred_logit)
#max(london$pred_logit)
#min(london$pred_probit)
#max(london$pred_probit)

```

In this first chart, we visualize the distribution of the predicted probabilities of the hotels being highly rated based on our linear probability model. The first obvious observation shows the major limitation of this model: The predicted probabilities range from -0.37 to 1.11, some of them being greater than 1 and even more being below 0. These probabilities obviously do not make economic sense. To get an idea about these extreme values, we looked at the average values of the covariates in the bottom and top 1% of the distribution. At the bottom, the average of stars is 1.88, the average distance from the center is 2.07 km and the mode of accomodation type is Bed and breakfast. As for the top 1%, the average of stars is 3.47, the average distance from the center is interestingly more at 2.6 km and the mode of accomodation type is Hotel. Besides these extremes, we can see some spikes in the distribution, the two biggest being at around 1/3 and 2/3.   

In the second chart we compare our LPM, logit and probit models by visualizing their predicted probabilities. As can be seen on the figure, the baseline is the predictions of the LPM that correspond to simply a 45 degree line. The predicted probabilities from the
logit and the probit are practically the same, but give higher estimates for higher values of LPM, and lower for lower values thant the LPM. The range of predicted values of the logit model is [0.007, 0.967], while for the probit it is [0.002,0.976]. These are obviously narrower than that of the LPM. 

## Conclusion
To conclude, the

