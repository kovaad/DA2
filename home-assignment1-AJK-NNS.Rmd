---
title: "DA2 - Gender Wage Gap Analysis"
author: "Adam Kovacs, Nam Son Nguyen"
date: "11/22/2021"
output: 
  pdf_document:
    toc: true
    fig_caption: true
    latex_engine: xelatex
---

```{r import, echo=FALSE, message=FALSE}
#clear memory
rm(list=ls())

#import packages
if (!require(pacman)){
  install.packages("pacman")
}

pacman::p_load(tidyverse, modelsummary, kableExtra, fixest, estimatr)

# import data
df_orig <- read_csv( 'https://osf.io/4ay9x/download' )

```

## Filtering for occupation

```{r filter, echo=FALSE}
# keep only two occupation types: Advertising and promotions managers and 
# Marketing and sales managers
df_orig <- df_orig %>% mutate(sample=ifelse(occ2012==0040,1,
                                              ifelse(occ2012 == 0050,2,0)))

df <- df_orig %>%
  filter(sample==1 | sample==2) %>%
  select(c("earnwke", "uhours", "grade92", "sex", "occ2012", "sample"))

#frequency table of men and women in the sample

#t <- table(df$occ2012,df$female)
#rownames(t) <- c("Advertising Mngr.", "Sales Mngr.")

#knitr::kable(t, col.names = c("Male", "Female"))

```

## Create new variables

```{r, echo=FALSE}
#generate female, wage, logwage, agesquared variables

df <- df %>% mutate(female=as.numeric(sex == 2),
                    w = earnwke/uhours,
                    lnw = log(w),
                    grade92 = relevel(as.factor(ifelse(grade92 == 34 | grade92 ==  37, 0, grade92)), ref = '46'))

```


## Descriptive statistics


```{r descriptives, echo=FALSE}

#create 5th and 95th percentiles

P95 <- function(x){quantile(x,0.95,na.rm=T)}
P05 <- function(x){quantile(x,0.05,na.rm=T)}

#create descriptive table
datasummary( (`Weekly earnings` = earnwke ) + (`Weekly hours worked` = uhours ) + 
               (`Hourly wage` = w ) ~
               Mean + Median + SD + Min + Max + P05 + P95, 
             data = df,
             title = 'Wage Metrics of Advertising and Sales Managers' ) %>% 
  kableExtra::kable_styling(latex_options = "hold_position")

```

What we can infer from the descriptives table is that there are couple fo individuals who do overtime beyond the average 40 hours per week (99 at maximum, which is strangely specific), thus them being at the long tail part of the distribution makes the sample distribution right-skewed. Regarding the standardized wage KPI, hourly wage, we can observe a relatively high average dispersion between data points (standard deviation is USD 16.56). Anomalies can also be detected after taking the range of hourly wages into account, as according to our sample, there can be the case that someone earns USD 0.03 per hour. We hardly believe that its possible in the US, therefore we will exclude extreme datapoint having lower than USD 1 as their hourly wage. Nothing extremely unusual can be detected when observing the 5th and 95th percentiles.

```{r cleaning, echo = FALSE}

# filter out posssible extreme values -- hourly wage should be at least 1 USD

df <- df %>% filter(w >= 1)
```

## Gender Wage Gap

Now that everything is in order, we can start to run our regressions to show whether the gender wage gap exists in this particular profession, and if so, what is the magnitude of the gap, what variables are the confounders in this relationship. As a baseline model, we have fitted a simple linear semi-elasticity regression with log wage being at the LHS and female dummy on the RHS.

Then, we started to extend our model with first including the level of education factor (7th or 8th grade being the baseline), followed by the age and squared value of age. 

```{r wage gap regressions, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

reg0 <- feols( w ~ female + grade92, data = df, vcov = "hetero" )

reg1 <- feols( lnw ~ female, data = df, vcov = "hetero" )

reg2 <- feols( lnw ~ female + grade92, data = df, vcov = "hetero" )

reg3 <- feols( lnw ~ female * grade92, data = df, vcov = "hetero" )



#reg3 <- feols( lnw ~ female + grade92 + age, data = df, vcov = "hetero" )

#reg4 <- feols( lnw ~ female + grade92 + age + agesq, data = df, vcov = "hetero" )

```

We've decided to present our results with the summary table below.

```{r, echo=FALSE}

msummary(list("Unconditional" = reg1, "Level-Level" = reg0, "Conditional" = reg2, "Interaction" =  reg3),
         fmt="%.2f",
         gof_omit = 'DF|Deviance|Log.Lik.|F|R2 Adj.|AIC|BIC|R2 Within|R2 Pseudo',
         stars=c('*' = .05, '**' = .01),
         estimate = "{estimate} ({std.error}){stars}",
         statistic = NULL,
         coef_rename = c("female" = "Female",
                         "grade920" = "No high school",
                         "grade9239" = "High school graduate",
                         "grade9240" = "College no degree",
                         "grade9241" = "Associate degree vocational",
                         "grade9242" = "Associate degree academic",
                         "grade9243" = "Bachelor's degree",
                         "grade9244" = "Master's degree",
                         "grade9245" = "Professional school",
                         "female:grade920" = "F x No high school",
                         "female:grade9239" = "F x High school graduate",
                         "female:grade9240" = "F x College no degree",
                         "female:grade9241" = "F x Associate degree vocational",
                         "female:grade9242" = "F x Associate degree academic",
                         "female:grade9243" = "F x Bachelor's degree",
                         "female:grade9244" = "F x Master's degree",
                         "female:grade9245" = "F x Professional school"),
         title = "Gender Wage Gap | Level of Education") %>% 
        column_spec(1:4, width = "7em") %>%
        row_spec(1:17, hline_after = T) %>% 
        kable_classic(full_width = F, position = "center" )

```

A female is expected to earn on average 25.5% less than a male in these professions This wage gap is significant at 5% significance level (even at 1%).

This gap tend to be slightly narrower if we include the level of educations, but the difference remains highly statistically significant. The additional variable also decreased the standard error of our female coefficient, all else being equal and multiplied our goodness-of-fit (17.2% of the log hourly wage's variance can be explained by the RHS). Therefore, we can say that the level of education is meaningful in the setup, as all of its coefficients are significant at the 5% level.

Moving onto Model 2 where we also included the age of employees, which had a marginal part in mediating the difference between sexes below 20%, ceteris paribus, while being a significant confounder. We also managed to further improve the R2 to 0.203.

Lastly, our last model have taken into consideration the possibility that the relationship between age and log hourly wake is non-linear. Hence, we included age as a polynomial of order two in the RHS. It seems as thought it was a reasonable decision by just looking at the significance of the variable and how much further it improved our fit (R2=0.235). As far as gender wage gap is concerned, a female tend to have averagely 19% lower hourly wage than a male working as a manager in Advertising & Sales.

We could go on-and-on in including possible mediators to our model, but considering that we have a sample just greater than 1,000 observations, we should carefully evaluate how much further we want to extend what we have. There are also unobservable variables such as effort, education quality, etc. which education level can only partly proxy for. Our models indicate that there is indeed a significant relationship between gender and wage, but the gap narrows as we control for other variables.

## Prediction

```{r, echo=FALSE, include=FALSE, warning=FALSE, message=FALSE}
#add predicted values and uncertainty metrics

z0 <- predict(reg0, df, se.fit=TRUE)
z1 <- predict(reg1, df, se.fit=TRUE)
z2 <- predict(reg2, df, se.fit=TRUE)
z3 <- predict(reg3, df, se.fit=TRUE)

#Conditioning on schooling

df<- df %>% mutate(wpred_f=z0[[1]],
                   wpred_fSE=z0[[2]],
                   wpred_fCIUP=wpred_f + 2*wpred_fSE,
                   wpred_fCILO=wpred_f - 2*wpred_fSE,
                   lnwpred_f=z1[[1]],
                   lnwpred_fSE=z1[[2]],
                   lnwpred_fCIUP=lnwpred_f + 2*lnwpred_fSE,
                   lnwpred_fCILO=lnwpred_f - 2*lnwpred_fSE,
                   lnwpred_fg=z2[[1]],
                   lnwpred_fgSE=z2[[2]],
                   lnwpred_fgCIUP=lnwpred_fg + 2*lnwpred_fgSE,
                   lnwpred_fgCILO=lnwpred_fg - 2*lnwpred_fgSE,
                   lnwpred_fxg=z3[[1]],
                   lnwpred_fxgSE=z3[[2]],
                   lnwpred_fxgCIUP=lnwpred_fxg + 2*lnwpred_fxgSE,
                   lnwpred_fxgCILO=lnwpred_fxg - 2*lnwpred_fxgSE
)

```{r, echo=FALSE, fig.height = 10, fig.width = 10}

#Relevel factors, and set facet names

levels(df$grade92) <- c("0", 39:46)

facet_names <- c(
                  `0` = "Male",
                  `1` = "Female"
                )

#Plotting

ggplot(data = df, aes(x=grade92, group=1)) +
  geom_point(aes(y=lnw), shape = 16, alpha = 0.5, size=0.5) +
  geom_line(aes(y = lnwpred_f, color = "Unconditional", linetype = "Unconditional"), size = 0.8)+
  geom_line(aes(y = lnwpred_fg,  color = "Conditional", linetype = "Conditional"), size = 0.8)+
  geom_line(aes(y = lnwpred_fxg,  color = "Interaction", linetype = "Interaction"), size = 0.8)+
  labs(title = "Predicted Log Hourly Earnings",
       subtitle = "Fitted values from our three regression models",
       x = "", 
       y = "Log Earnings (per hour)",
       color  = "Model", linetype = "Model", shape = "Model") +
  scale_x_discrete(labels=c("0" = "No High school", "39" = "High school graduate", "40" = "Some school but no degree", "41" = "Vocational degree", "42" = "Academic degree", "43" = "Bachelors" , "44" = "Masters", "45" = "Professional degree", "46" = "Doctorate degree")) +
  scale_color_viridis_d() +
  theme_bw() +
  theme(axis.text.x = element_text(angle=90),
        legend.position = "top") +
  facet_grid(female~., labeller=as_labeller(facet_names))

```




